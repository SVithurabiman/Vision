{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Q1 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3md/CXloaL7eXb6/yuDue",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SVithurabiman/Vision/blob/main/Q1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4JLLkOLmjek"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDyqYqyqmjPU"
      },
      "source": [
        "Q1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPmgy5DU2-n6",
        "outputId": "35e8931c-c26f-4e12-ca97-d68379ad5f3b"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "print('x_train:', x_train.shape)\n",
        "K = len(np.unique(y_train)) # Classes\n",
        "Ntr = x_train.shape[0]\n",
        "Nte = x_test.shape[0]\n",
        "Din = 3072 # CIFAR10\n",
        "# Din = 784 # MINIST\n",
        "# Normalize pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "mean_image = np.mean(x_train, axis=0)\n",
        "x_train = x_train - mean_image\n",
        "x_test = x_test - mean_image\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
        "x_train = np.reshape(x_train,(Ntr,Din))\n",
        "x_test = np.reshape(x_test,(Nte,Din))\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "\n",
        "print('x_train',x_train.shape)\n",
        "print('x_test',x_test.shape)\n",
        "std=1e-5\n",
        "w1 = std*np.random.randn(Din, K)\n",
        "b1 = np.zeros(K)\n",
        "print(\"w1:\", w1.shape)\n",
        "print(\"b1:\", b1.shape)\n",
        "\n",
        "\n",
        "batch_size = Ntr\n",
        "iterations =301\n",
        "lr =1.2e-2\n",
        "lr_decay=0.999\n",
        "reg =1e-6\n",
        "loss_history = []\n",
        "train_acc_history = []\n",
        "train_acc_history_2 = []\n",
        "lr_hist=[]\n",
        "val_acc_history = []\n",
        "test_loss=[]\n",
        "seed = 0\n",
        "#rng = np.random.default_rng(seed=seed)\n",
        "\n",
        "\n",
        "#Gradient Descent\n",
        "for t in range(iterations):\n",
        "    # Forward pass\n",
        "  \n",
        "    h=x_train.dot(w1)+b1\n",
        "\n",
        "    loss=(1/(batch_size))*(np.sum((h-y_train)**2))+reg*np.sum(w1*w1)\n",
        "    loss_history.append(loss)\n",
        "\n",
        "\n",
        "    # Backward pass\n",
        "    dw1 = (2/batch_size)*((x_train.T.dot(h - y_train))  + reg*w1)\n",
        "    db1=2*(1/batch_size)*(sum((h-y_train),0))\n",
        "    b1=b1-lr*db1\n",
        "\n",
        "    lr_hist.append(lr)\n",
        "    h=x_test.dot(w1)+b1\n",
        "\n",
        "    t_loss=(1/(Nte))*(np.sum((h-y_test)**2))+reg*np.sum(w1*w1)\n",
        "    test_loss.append(t_loss)\n",
        "\n",
        "    \n",
        "    valid_pred = [np.argmax(x_train.dot(w1)+b1, axis=1) == np.argmax(y_train,axis=1)]\n",
        "    temp=np.sum(valid_pred)/len(np.argmax(y_train,axis=1))\n",
        "\n",
        "    train_acc_history.append(temp)\n",
        "\n",
        "    valid_pred = [np.argmax(x_test.dot(w1)+b1, axis=1) == np.argmax(y_test,axis=1)]\n",
        "    temp=np.sum(valid_pred)/len(np.argmax(y_test,axis=1))\n",
        "    val_acc_history.append(temp)\n",
        "    w1 -= lr*dw1\n",
        "    lr = lr*lr_decay\n",
        "\n",
        "    if ((t+1)%10==0) or (t==1) or (t==2) or(t==0):\n",
        "        print(\"Epoch\",t+1, \"|\", \"Training Loss\",loss_history[-1],\"|\", \"Training Acc:\",train_acc_history[-1],'|', \"Test Loss\",test_loss[-1],\"|\",'Validation Acc:',val_acc_history[-1] ,'|','Learning Rate:',lr)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train: (50000, 32, 32, 3)\n",
            "x_train (50000, 3072)\n",
            "x_test (10000, 3072)\n",
            "w1: (3072, 10)\n",
            "b1: (10,)\n",
            "w1 (3072, 10)\n",
            "Epoch 1 | Training Loss 1.000029360102773 | Training Acc: 0.08748 | Test Loss 0.9952879384609945 | Validation Acc: 0.0889 | Learning Rate: 0.011988\n",
            "Epoch 2 | Training Loss 0.9594390225491414 | Training Acc: 0.2442 | Test Loss 0.9536474715424385 | Validation Acc: 0.2485 | Learning Rate: 0.011976012000000001\n",
            "Epoch 3 | Training Loss 0.9416141918493344 | Training Acc: 0.29088 | Test Loss 0.9366198779109014 | Validation Acc: 0.2963 | Learning Rate: 0.011964035988\n",
            "Epoch 10 | Training Loss 0.8886563128054076 | Training Acc: 0.34428 | Test Loss 0.885120277347032 | Validation Acc: 0.3447 | Learning Rate: 0.011880538562516979\n",
            "Epoch 20 | Training Loss 0.8529477636358548 | Training Acc: 0.36698 | Test Loss 0.8508701721191638 | Validation Acc: 0.3679 | Learning Rate: 0.011762266377954415\n",
            "Epoch 30 | Training Loss 0.8322571455382886 | Training Acc: 0.37718 | Test Loss 0.8310954369303345 | Validation Acc: 0.3781 | Learning Rate: 0.011645171607157025\n",
            "Epoch 40 | Training Loss 0.8193086005790929 | Training Acc: 0.38426 | Test Loss 0.8187704071593305 | Validation Acc: 0.3844 | Learning Rate: 0.011529242528829739\n",
            "Epoch 50 | Training Loss 0.8109062947137664 | Training Acc: 0.38884 | Test Loss 0.8108247720003123 | Validation Acc: 0.3875 | Learning Rate: 0.011414467538364375\n",
            "Epoch 60 | Training Loss 0.8052758681424691 | Training Acc: 0.39322 | Test Loss 0.805552299623637 | Validation Acc: 0.3903 | Learning Rate: 0.011300835146678019\n",
            "Epoch 70 | Training Loss 0.8013731502888547 | Training Acc: 0.39602 | Test Loss 0.8019469894023148 | Validation Acc: 0.3919 | Learning Rate: 0.011188333979062952\n",
            "Epoch 80 | Training Loss 0.7985685337857295 | Training Acc: 0.39794 | Test Loss 0.7994010949665006 | Validation Acc: 0.3931 | Learning Rate: 0.011076952774048035\n",
            "Epoch 90 | Training Loss 0.7964761625856 | Training Acc: 0.4002 | Test Loss 0.7975415114091937 | Validation Acc: 0.3941 | Learning Rate: 0.010966680382271426\n",
            "Epoch 100 | Training Loss 0.7948561824649508 | Training Acc: 0.40186 | Test Loss 0.796135959778624 | Validation Acc: 0.3946 | Learning Rate: 0.01085750576536451\n",
            "Epoch 110 | Training Loss 0.7935573802017317 | Training Acc: 0.40362 | Test Loss 0.7950378257398176 | Validation Acc: 0.3962 | Learning Rate: 0.010749417994846957\n",
            "Epoch 120 | Training Loss 0.7924829929124481 | Training Acc: 0.40478 | Test Loss 0.7941532168958063 | Validation Acc: 0.3964 | Learning Rate: 0.01064240625103277\n",
            "Epoch 130 | Training Loss 0.7915700809016218 | Training Acc: 0.4059 | Test Loss 0.7934210505867126 | Validation Acc: 0.3958 | Learning Rate: 0.010536459821947215\n",
            "Epoch 140 | Training Loss 0.7907769526236383 | Training Acc: 0.40724 | Test Loss 0.7928008911163862 | Validation Acc: 0.3954 | Learning Rate: 0.010431568102254556\n",
            "Epoch 150 | Training Loss 0.7900754239045592 | Training Acc: 0.40884 | Test Loss 0.7922654478658724 | Validation Acc: 0.3971 | Learning Rate: 0.010327720592196441\n",
            "Epoch 160 | Training Loss 0.7894460079445569 | Training Acc: 0.41002 | Test Loss 0.7917959043479473 | Validation Acc: 0.3975 | Learning Rate: 0.010224906896540875\n",
            "Epoch 170 | Training Loss 0.7888748979713804 | Training Acc: 0.41066 | Test Loss 0.7913789822364475 | Validation Acc: 0.3982 | Learning Rate: 0.010123116723541641\n",
            "Epoch 180 | Training Loss 0.7883520556563551 | Training Acc: 0.41152 | Test Loss 0.7910050777809362 | Validation Acc: 0.3986 | Learning Rate: 0.010022339883908084\n",
            "Epoch 190 | Training Loss 0.7878699872299918 | Training Acc: 0.41176 | Test Loss 0.7906670665859166 | Validation Acc: 0.3994 | Learning Rate: 0.00992256628978516\n",
            "Epoch 200 | Training Loss 0.7874229508435775 | Training Acc: 0.41266 | Test Loss 0.7903595284236735 | Validation Acc: 0.4 | Learning Rate: 0.009823785953743634\n",
            "Epoch 210 | Training Loss 0.7870064366726109 | Training Acc: 0.41312 | Test Loss 0.7900782382732803 | Validation Acc: 0.4006 | Learning Rate: 0.00972598898778032\n",
            "Epoch 220 | Training Loss 0.7866168210724925 | Training Acc: 0.41398 | Test Loss 0.7898198276079413 | Validation Acc: 0.4012 | Learning Rate: 0.009629165602328297\n",
            "Epoch 230 | Training Loss 0.7862511328842611 | Training Acc: 0.4145 | Test Loss 0.7895815555907515 | Validation Acc: 0.4012 | Learning Rate: 0.009533306105276949\n",
            "Epoch 240 | Training Loss 0.7859068927686187 | Training Acc: 0.4148 | Test Loss 0.7893611519551262 | Validation Acc: 0.4015 | Learning Rate: 0.00943840090100178\n",
            "Epoch 250 | Training Loss 0.7855820006483325 | Training Acc: 0.41494 | Test Loss 0.7891567071653041 | Validation Acc: 0.4023 | Learning Rate: 0.009344440489403886\n",
            "Epoch 260 | Training Loss 0.7852746552524252 | Training Acc: 0.41566 | Test Loss 0.7889665941462144 | Validation Acc: 0.4033 | Learning Rate: 0.00925141546495899\n",
            "Epoch 270 | Training Loss 0.7849832953879605 | Training Acc: 0.4162 | Test Loss 0.7887894113793185 | Validation Acc: 0.4031 | Learning Rate: 0.009159316515775937\n",
            "Epoch 280 | Training Loss 0.7847065561495601 | Training Acc: 0.41688 | Test Loss 0.7886239406745077 | Validation Acc: 0.4032 | Learning Rate: 0.009068134422664556\n",
            "Epoch 290 | Training Loss 0.784443235574634 | Training Acc: 0.41734 | Test Loss 0.7884691151861689 | Validation Acc: 0.4036 | Learning Rate: 0.008977860058212824\n",
            "Epoch 300 | Training Loss 0.7841922687370644 | Training Acc: 0.41768 | Test Loss 0.7883239947040189 | Validation Acc: 0.4041 | Learning Rate: 0.008888484385873198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6oyIXEKmh1T"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "OrvIBR6KBNKe",
        "outputId": "6860ec8f-78dd-4478-cf81-0398cad04500"
      },
      "source": [
        "fig, ax = plt.subplots(1,5, figsize=(30,6))\n",
        "ax[0].plot(loss_history)\n",
        "ax[0].set_ylim(0.7,1.05)\n",
        "ax[1].plot(train_acc_history)\n",
        "ax[1].set_ylim(0.05,0.47)\n",
        "ax[2].set_ylim(0.05,0.47)\n",
        "ax[3].plot(val_acc_history)\n",
        "ax[4].plot(lr_hist)\n",
        "ax[4].set_ylim(0.005,0.014)\n",
        "ax[2].plot(test_loss)\n",
        "ax[2].set_ylim(0.7,1.05)\n",
        "\n",
        "\n",
        "ax[0].set_title('Training Loss')\n",
        "ax[1].set_title('Training Set Accuracy')\n",
        "\n",
        "ax[2].set_title('Test Loss')\n",
        "ax[3].set_title('Test Set Accuracy')\n",
        "ax[4].set_title('Learning Rate')\n",
        "\n",
        "w =  w1- np.min(w1)# Making the minimum weight zero.\n",
        "image = ((w/np.max(w))*255).astype('uint8')\n",
        "class_label = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "fig, axes  = plt.subplots(2,5, sharex='all', sharey='all', figsize=(25,10))\n",
        "#location = 1 # Location of the image in the grid of 2x5\n",
        "for i in range(K):\n",
        "    out = images[:,i].reshape(32,32,3)\n",
        "    plt.subplot(2,5,i+1),plt.imshow(out[:,:,::-1])\n",
        "    title=\"Class:\"+str(class_label[i])\n",
        "    plt.title(title) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fe958ac6777d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.47\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    }
  ]
}